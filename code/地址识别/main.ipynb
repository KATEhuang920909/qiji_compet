{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * 环境更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install --upgrade paddle -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install --upgrade paddlepaddle -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install --upgrade paddlenlp -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paddle\n",
    "paddle.is_compiled_with_cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T03:06:31.009881600Z",
     "start_time": "2024-02-19T03:06:30.947921900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:39:36.315161Z",
     "iopub.status.busy": "2024-02-18T06:39:36.314608Z",
     "iopub.status.idle": "2024-02-18T06:39:38.367285Z",
     "shell.execute_reply": "2024-02-18T06:39:38.365984Z",
     "shell.execute_reply.started": "2024-02-18T06:39:36.315128Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.datasets import MapDataset\n",
    "from paddlenlp.data import Stack, Pad, Tuple\n",
    "from paddlenlp.metrics import ChunkEvaluator\n",
    "import paddle.nn.functional as F\n",
    "import numpy as np\n",
    "from functools import partial #partial()函数可以用来固定某些参数值，并返回一个新的callable对象\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-14T12:03:57.314261Z",
     "iopub.status.busy": "2022-05-14T12:03:57.313459Z",
     "iopub.status.idle": "2022-05-14T12:03:57.546868Z",
     "shell.execute_reply": "2022-05-14T12:03:57.545807Z",
     "shell.execute_reply.started": "2022-05-14T12:03:57.314224Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浙 B-prov\r\n",
      "江 E-prov\r\n",
      "杭 B-city\r\n",
      "州 I-city\r\n",
      "市 E-city\r\n",
      "江 B-district\r\n",
      "干 I-district\r\n",
      "区 E-district\r\n",
      "九 B-town\r\n",
      "堡 I-town\r\n"
     ]
    }
   ],
   "source": [
    "!head -n10 data/train.conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-14T12:04:55.576110Z",
     "iopub.status.busy": "2022-05-14T12:04:55.575580Z",
     "iopub.status.idle": "2022-05-14T12:04:55.808276Z",
     "shell.execute_reply": "2022-05-14T12:04:55.807205Z",
     "shell.execute_reply.started": "2022-05-14T12:04:55.576068Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "杭 B-city\r\n",
      "州 E-city\r\n",
      "五 B-poi\r\n",
      "洲 I-poi\r\n",
      "国 I-poi\r\n",
      "际 E-poi\r\n",
      "\r\n",
      "浙 B-prov\r\n",
      "江 I-prov\r\n",
      "省 E-prov\r\n"
     ]
    }
   ],
   "source": [
    "!head -n10  data/dev.conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-14T12:05:34.525567Z",
     "iopub.status.busy": "2022-05-14T12:05:34.525092Z",
     "iopub.status.idle": "2022-05-14T12:05:34.756843Z",
     "shell.execute_reply": "2022-05-14T12:05:34.755927Z",
     "shell.execute_reply.started": "2022-05-14T12:05:34.525532Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\u0001朝阳区小关北里000-0号\r\n",
      "2\u0001朝阳区惠新东街00号\r\n",
      "3\u0001朝阳区南磨房路与西大望路交口东南角\r\n",
      "4\u0001朝阳区潘家园南里00号\r\n",
      "5\u0001朝阳区向军南里二巷0号附近\r\n",
      "6\u0001朝阳区多处营业网点\r\n",
      "7\u0001朝阳区多处营业网点\r\n",
      "8\u0001朝阳区多处营业网点\r\n",
      "9\u0001朝阳区北三环中路00号商房大厦0楼\r\n",
      "10\u0001朝阳区孙河乡康营家园00区北侧底商\r\n"
     ]
    }
   ],
   "source": [
    "!head data/final_test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **数据处理已经预先处理好，后面需要转为序列，模型需要的数据。构建batch**\n",
    "\n",
    "# 1.数据和标签分开，把实体类别转为id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:39:39.304004Z",
     "iopub.status.busy": "2024-02-18T06:39:39.303319Z",
     "iopub.status.idle": "2024-02-18T06:39:39.312676Z",
     "shell.execute_reply": "2024-02-18T06:39:39.311689Z",
     "shell.execute_reply.started": "2024-02-18T06:39:39.303965Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#加载数据文件datafiles\n",
    "def load_dataset(datafiles):\n",
    "    #读取数据文件data_path\n",
    "    def read(data_path):\n",
    "        with open(data_path, 'r', encoding='utf-8') as fp:\n",
    "            next(fp)  # Skip header  #Deleted by WGM\n",
    "            #处理每行数据（文本+‘\\t’+标注）\n",
    "            for line in fp.readlines():\n",
    "                #提取文本和标注\n",
    "                words, labels = line.strip('\\n').split('\\t')\n",
    "                #文本中单字和标注构成的数组\n",
    "                words = words.split('\\002')\n",
    "                labels = labels.split('\\002')\n",
    "                #迭代返回文本和标注\n",
    "                yield words, labels\n",
    "    \n",
    "    #根据datafiles的数据类型，选择合适的处理方式\n",
    "    if isinstance(datafiles, str):#字符串，单个文件名称\n",
    "        #返回单个文件对应的单个数据集\n",
    "        return MapDataset(list(read(datafiles)))\n",
    "    elif isinstance(datafiles, list) or isinstance(datafiles, tuple):#列表或元组，多个文件名称\n",
    "        #返回多个文件对应的多个数据集\n",
    "        return [MapDataset(list(read(datafile))) for datafile in datafiles]\n",
    "        \n",
    "#加载字典文件，文件由单列构成，需要设置value\n",
    "def load_dict_single(dict_path):\n",
    "    #字典初始化为空\n",
    "    vocab = {}\n",
    "    #value是自增数值，从0开始\n",
    "    i = 0\n",
    "    #逐行读取字典文件\n",
    "    for line in open(dict_path, 'r', encoding='utf-8'):\n",
    "        #将每行文字设置为key\n",
    "        key = line.strip('\\n')\n",
    "        #设置对应的value\n",
    "        vocab[key] = i\n",
    "        i+=1\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:39:41.083276Z",
     "iopub.status.busy": "2024-02-18T06:39:41.082558Z",
     "iopub.status.idle": "2024-02-18T06:39:41.291659Z",
     "shell.execute_reply": "2024-02-18T06:39:41.290504Z",
     "shell.execute_reply.started": "2024-02-18T06:39:41.083230Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 8854\r\n",
      "测试集集大小: 1969\r\n",
      "(['浙', '江', '省', '温', '州', '市', '平', '阳', '县', '海', '西', '镇', '宋', '埠', '公', '园', '南', '路', '0', '0', '0', '0', '号'], ['B-prov', 'I-prov', 'E-prov', 'B-city', 'I-city', 'E-city', 'B-district', 'I-district', 'E-district', 'B-town', 'I-town', 'E-town', 'B-poi', 'I-poi', 'I-poi', 'E-poi', 'B-road', 'E-road', 'B-roadno', 'I-roadno', 'I-roadno', 'I-roadno', 'E-roadno'])\r\n",
      "(['浙', '江', '省', '杭', '州', '市', '余', '杭', '乔', '司', '街', '道', '博', '卡', '路', '0', '号', '博', '卡', '制', '衣'], ['B-prov', 'I-prov', 'E-prov', 'B-city', 'I-city', 'E-city', 'B-district', 'E-district', 'B-town', 'I-town', 'I-town', 'E-town', 'B-road', 'I-road', 'E-road', 'B-roadno', 'E-roadno', 'B-poi', 'I-poi', 'I-poi', 'E-poi'])\r\n",
      "{'B-prov': 0, 'E-prov': 1, 'B-city': 2, 'I-city': 3, 'E-city': 4, 'B-district': 5, 'I-district': 6, 'E-district': 7, 'B-town': 8, 'I-town': 9, 'E-town': 10, 'B-community': 11, 'I-community': 12, 'E-community': 13, 'B-poi': 14, 'E-poi': 15, 'I-prov': 16, 'I-poi': 17, 'B-road': 18, 'E-road': 19, 'B-roadno': 20, 'I-roadno': 21, 'E-roadno': 22, 'I-road': 23, 'O': 24, 'B-subpoi': 25, 'I-subpoi': 26, 'E-subpoi': 27, 'B-devzone': 28, 'I-devzone': 29, 'E-devzone': 30, 'B-houseno': 31, 'I-houseno': 32, 'E-houseno': 33, 'B-intersection': 34, 'I-intersection': 35, 'E-intersection': 36, 'B-assist': 37, 'I-assist': 38, 'E-assist': 39, 'B-cellno': 40, 'I-cellno': 41, 'E-cellno': 42, 'B-floorno': 43, 'E-floorno': 44, 'S-assist': 45, 'I-floorno': 46, 'B-distance': 47, 'I-distance': 48, 'E-distance': 49, 'B-village_group': 50, 'E-village_group': 51, 'I-village_group': 52, 'S-poi': 53, 'S-intersection': 54, 'S-district': 55, 'S-community': 56}\r\n"
     ]
    }
   ],
   "source": [
    "#把数据集转为当个字符\n",
    "train_ds, dev_ds = load_dataset(datafiles=('./data/train.txt', './data/dev.txt'))\n",
    "\n",
    "#把类别名转为id\n",
    "label_vocab = load_dict_single('./data/mytag.dic')\n",
    "\n",
    "#查看训练集和测试集的大小\n",
    "print(\"训练集大小:\",len(train_ds))\n",
    "print(\"测试集集大小:\",len(dev_ds))\n",
    "print(train_ds[0])\n",
    "print(dev_ds[0])\n",
    "print(label_vocab) #57个分类\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.加载bert分词器，对数据进行序列化，数据处理成模型想要的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:39:43.579750Z",
     "iopub.status.busy": "2024-02-18T06:39:43.579119Z",
     "iopub.status.idle": "2024-02-18T06:39:43.586328Z",
     "shell.execute_reply": "2024-02-18T06:39:43.585351Z",
     "shell.execute_reply.started": "2024-02-18T06:39:43.579714Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_example(example,tokenizer,label_vocab,max_seq_len=128,is_test=False):\n",
    "    #测试集没有标签\n",
    "    if is_test:\n",
    "        text = example\n",
    "    else:\n",
    "        text, label = example\n",
    "    tokenizer_input = tokenizer.encode(text=text, max_seq_len=None, pad_to_max_seq_len=False,return_length=True)\n",
    "    input_ids = tokenizer_input[\"input_ids\"]\n",
    "    token_type_ids = tokenizer_input[\"token_type_ids\"]\n",
    "    seq_len = tokenizer_input[\"seq_len\"]\n",
    "    if not is_test:\n",
    "        # 加入cls和sep\n",
    "        label = ['O']+label+['O']\n",
    "        # 将标签转为序列\n",
    "        label = [label_vocab[x] for x in label]\n",
    "        return input_ids, token_type_ids, seq_len, label\n",
    "    else: # 测试集，不返回标签\n",
    "        return input_ids, token_type_ids, seq_len\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:39:45.586799Z",
     "iopub.status.busy": "2024-02-18T06:39:45.586140Z",
     "iopub.status.idle": "2024-02-18T06:39:45.606342Z",
     "shell.execute_reply": "2024-02-18T06:39:45.605328Z",
     "shell.execute_reply.started": "2024-02-18T06:39:45.586759Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-18 14:39:45,588] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\r\n"
     ]
    }
   ],
   "source": [
    "#加载TinyBert的Tokenizer\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained('ernie-1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:39:49.369354Z",
     "iopub.status.busy": "2024-02-18T06:39:49.368691Z",
     "iopub.status.idle": "2024-02-18T06:39:49.374270Z",
     "shell.execute_reply": "2024-02-18T06:39:49.373244Z",
     "shell.execute_reply.started": "2024-02-18T06:39:49.369316Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#偏函数，固定参数\n",
    "trans_func = partial(convert_example, tokenizer=tokenizer, label_vocab=label_vocab, max_seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:39:50.917230Z",
     "iopub.status.busy": "2024-02-18T06:39:50.915960Z",
     "iopub.status.idle": "2024-02-18T06:39:50.923173Z",
     "shell.execute_reply": "2024-02-18T06:39:50.922296Z",
     "shell.execute_reply.started": "2024-02-18T06:39:50.917190Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 1382, 409, 244, 565, 404, 99, 157, 507, 308, 233, 213, 484, 945, 3074, 53, 509, 219, 216, 540, 540, 540, 540, 500, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 25, [24, 0, 16, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 14, 17, 17, 15, 18, 19, 20, 21, 21, 21, 22, 24])\r\n"
     ]
    }
   ],
   "source": [
    "#对数据集进行编码（转为TinyBert需要的格式）\n",
    "train_ds.map(trans_func)\n",
    "dev_ds.map(trans_func)\n",
    "print(train_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:39:52.459853Z",
     "iopub.status.busy": "2024-02-18T06:39:52.458608Z",
     "iopub.status.idle": "2024-02-18T06:39:52.466201Z",
     "shell.execute_reply": "2024-02-18T06:39:52.465273Z",
     "shell.execute_reply.started": "2024-02-18T06:39:52.459808Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#数据组装成一个batch一个batch\n",
    "\n",
    "#创建Tuple对象，将多个批处理函数的处理结果连接在一起\n",
    "ignore_label = -1\n",
    "#因为数据集train_ds、dev_ds的每条数据包含4部分，所以Tuple对象中包含4个批处理函数\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    #将每条数据的input_ids组合为数组，如果input_ids不等长，那么填充为pad_val\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),\n",
    "    #将每条数据的segment_ids组合为数组，如果segment_ids不等长，那么填充为pad_val\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),\n",
    "    #将每条数据的seq_len组合为数组\n",
    "    Stack(),\n",
    "    #将每条数据的label组合为数组，如果label不等长，那么填充为pad_val\n",
    "    Pad(axis=0, pad_val=ignore_label)\n",
    "): fn(samples)\n",
    "\n",
    "#paddle.io.DataLoader加载给定数据集，返回迭代器，每次迭代访问batch_size条数据\n",
    "#使用collate_fn定义所读取数据的格式\n",
    "#训练集\n",
    "train_loader = paddle.io.DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=32,\n",
    "    return_list=True,\n",
    "    collate_fn=batchify_fn)\n",
    "#验证集\n",
    "dev_loader = paddle.io.DataLoader(\n",
    "    dataset=dev_ds,\n",
    "    batch_size=32,\n",
    "    return_list=True,\n",
    "    collate_fn=batchify_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 组合TinyBert+BiGRU+CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:39:59.962020Z",
     "iopub.status.busy": "2024-02-18T06:39:59.961476Z",
     "iopub.status.idle": "2024-02-18T06:39:59.966035Z",
     "shell.execute_reply": "2024-02-18T06:39:59.965317Z",
     "shell.execute_reply.started": "2024-02-18T06:39:59.961983Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle.nn as nn\n",
    "from paddlenlp.transformers import ErnieModel\n",
    "from paddlenlp.layers.crf import LinearChainCrf, LinearChainCrfLoss, ViterbiDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:40:04.650614Z",
     "iopub.status.busy": "2024-02-18T06:40:04.649575Z",
     "iopub.status.idle": "2024-02-18T06:40:04.657578Z",
     "shell.execute_reply": "2024-02-18T06:40:04.656837Z",
     "shell.execute_reply.started": "2024-02-18T06:40:04.650570Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TinyBertGRUCRF(nn.Layer):\n",
    "    def __init__(self,tinyBert,gru_hidden_size=300,\n",
    "                num_class=2,\n",
    "                crf_lr=100):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_class\n",
    "        self.tinyBert = tinyBert\n",
    "        self.gru = nn.GRU(self.tinyBert.config[\"hidden_size\"],\n",
    "                          gru_hidden_size,\n",
    "                          num_layers = 2,\n",
    "                          direction='bidirect')\n",
    "        self.fc = nn.Linear(gru_hidden_size*2,num_class+2)\n",
    "        self.crf = LinearChainCrf(self.num_classes)\n",
    "        self.crf_loss = LinearChainCrfLoss(self.crf)\n",
    "        self.viterbi_decoder = ViterbiDecoder(self.crf.transitions)\n",
    "\n",
    "    def forward(self,input_ids,token_type_ids,lengths=None,labels=None):\n",
    "        encoder_output,_ = self.tinyBert(input_ids, token_type_ids = token_type_ids)\n",
    "        gru_output, _ = self.gru(encoder_output)\n",
    "        emission = self.fc(gru_output)\n",
    "        if labels is not None:\n",
    "            loss = self.crf_loss(emission, lengths, labels)\n",
    "            return loss\n",
    "        else:\n",
    "            _,prediction = self.viterbi_decoder(emission, lengths)\n",
    "            return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:40:07.376365Z",
     "iopub.status.busy": "2024-02-18T06:40:07.375833Z",
     "iopub.status.idle": "2024-02-18T06:40:11.560170Z",
     "shell.execute_reply": "2024-02-18T06:40:11.559274Z",
     "shell.execute_reply.started": "2024-02-18T06:40:07.376330Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-02-18 14:40:07,378] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\r\n",
      "W0218 14:40:07.381999   641 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 12.0, Runtime API Version: 10.1\r\n",
      "W0218 14:40:07.387120   641 device_context.cc:465] device: 0, cuDNN Version: 7.6.\r\n",
      "[2024-02-18 14:40:11,264] [    INFO] - Weights from pretrained model not used in ErnieModel: ['cls.predictions.layer_norm.weight', 'cls.predictions.decoder_bias', 'cls.predictions.transform.bias', 'cls.predictions.transform.weight', 'cls.predictions.layer_norm.bias']\r\n"
     ]
    }
   ],
   "source": [
    "#加载预训练模型TinyBert\n",
    "tinybert = ErnieModel.from_pretrained('ernie-1.0')\n",
    "model = TinyBertGRUCRF(tinybert, 300, len(label_vocab), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:40:13.769090Z",
     "iopub.status.busy": "2024-02-18T06:40:13.768541Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的当前epoch:0 - step:1\r\n",
      "损失函数: 80.013527\r\n",
      "训练集的当前epoch:0 - step:11\r\n",
      "损失函数: 66.766640\r\n",
      "训练集的当前epoch:0 - step:21\r\n",
      "损失函数: 56.832478\r\n",
      "训练集的当前epoch:0 - step:31\r\n",
      "损失函数: 48.255463\r\n",
      "训练集的当前epoch:0 - step:41\r\n",
      "损失函数: 44.758476\r\n",
      "训练集的当前epoch:0 - step:51\r\n",
      "损失函数: 38.669243\r\n",
      "训练集的当前epoch:0 - step:61\r\n",
      "损失函数: 34.507248\r\n",
      "训练集的当前epoch:0 - step:71\r\n",
      "损失函数: 29.148651\r\n",
      "训练集的当前epoch:0 - step:81\r\n",
      "损失函数: 29.373930\r\n",
      "训练集的当前epoch:0 - step:91\r\n",
      "损失函数: 28.151989\r\n",
      "训练集的当前epoch:0 - step:101\r\n",
      "损失函数: 21.719574\r\n",
      "训练集的当前epoch:0 - step:111\r\n",
      "损失函数: 21.785767\r\n",
      "训练集的当前epoch:0 - step:121\r\n",
      "损失函数: 21.802521\r\n",
      "训练集的当前epoch:0 - step:131\r\n",
      "损失函数: 17.572851\r\n",
      "训练集的当前epoch:0 - step:141\r\n",
      "损失函数: 14.919171\r\n",
      "训练集的当前epoch:0 - step:151\r\n",
      "损失函数: 15.116917\r\n",
      "训练集的当前epoch:0 - step:161\r\n",
      "损失函数: 12.999769\r\n",
      "训练集的当前epoch:0 - step:171\r\n",
      "损失函数: 13.329678\r\n",
      "训练集的当前epoch:0 - step:181\r\n",
      "损失函数: 10.552842\r\n",
      "训练集的当前epoch:0 - step:191\r\n",
      "损失函数: 10.812273\r\n",
      "训练集的当前epoch:0 - step:201\r\n",
      "损失函数: 9.820799\r\n",
      "训练集的当前epoch:0 - step:211\r\n",
      "损失函数: 10.503597\r\n",
      "训练集的当前epoch:0 - step:221\r\n",
      "损失函数: 10.150091\r\n",
      "训练集的当前epoch:0 - step:231\r\n",
      "损失函数: 8.699288\r\n",
      "训练集的当前epoch:0 - step:241\r\n",
      "损失函数: 10.400190\r\n",
      "训练集的当前epoch:0 - step:251\r\n",
      "损失函数: 7.768298\r\n",
      "训练集的当前epoch:0 - step:261\r\n",
      "损失函数: 8.461512\r\n",
      "训练集的当前epoch:0 - step:271\r\n",
      "损失函数: 7.365589\r\n",
      "评估准确度: 0.953149 - 召回率: 0.916278 - f1得分: 0.934350\r\n",
      "训练集的当前epoch:1 - step:4\r\n",
      "损失函数: 9.054243\r\n",
      "训练集的当前epoch:1 - step:14\r\n",
      "损失函数: 5.766478\r\n",
      "训练集的当前epoch:1 - step:24\r\n",
      "损失函数: 8.255881\r\n",
      "训练集的当前epoch:1 - step:34\r\n",
      "损失函数: 8.321101\r\n",
      "训练集的当前epoch:1 - step:44\r\n",
      "损失函数: 8.290565\r\n",
      "训练集的当前epoch:1 - step:54\r\n",
      "损失函数: 6.825688\r\n",
      "训练集的当前epoch:1 - step:64\r\n",
      "损失函数: 4.690255\r\n",
      "训练集的当前epoch:1 - step:74\r\n",
      "损失函数: 4.273888\r\n",
      "训练集的当前epoch:1 - step:84\r\n",
      "损失函数: 9.426343\r\n",
      "训练集的当前epoch:1 - step:94\r\n",
      "损失函数: 5.394198\r\n",
      "训练集的当前epoch:1 - step:104\r\n",
      "损失函数: 6.424173\r\n",
      "训练集的当前epoch:1 - step:114\r\n",
      "损失函数: 5.370747\r\n",
      "训练集的当前epoch:1 - step:124\r\n",
      "损失函数: 6.509522\r\n",
      "训练集的当前epoch:1 - step:134\r\n",
      "损失函数: 5.896172\r\n",
      "训练集的当前epoch:1 - step:144\r\n",
      "损失函数: 6.705034\r\n",
      "训练集的当前epoch:1 - step:154\r\n",
      "损失函数: 4.918301\r\n",
      "训练集的当前epoch:1 - step:164\r\n",
      "损失函数: 4.775265\r\n",
      "训练集的当前epoch:1 - step:174\r\n",
      "损失函数: 7.378504\r\n",
      "训练集的当前epoch:1 - step:184\r\n",
      "损失函数: 5.270228\r\n",
      "训练集的当前epoch:1 - step:194\r\n",
      "损失函数: 4.976871\r\n",
      "训练集的当前epoch:1 - step:204\r\n",
      "损失函数: 6.742535\r\n",
      "训练集的当前epoch:1 - step:214\r\n",
      "损失函数: 3.684944\r\n",
      "训练集的当前epoch:1 - step:224\r\n",
      "损失函数: 4.442997\r\n",
      "训练集的当前epoch:1 - step:234\r\n",
      "损失函数: 4.890617\r\n",
      "训练集的当前epoch:1 - step:244\r\n",
      "损失函数: 6.643988\r\n",
      "训练集的当前epoch:1 - step:254\r\n",
      "损失函数: 5.506747\r\n",
      "训练集的当前epoch:1 - step:264\r\n",
      "损失函数: 4.225261\r\n",
      "训练集的当前epoch:1 - step:274\r\n",
      "损失函数: 3.334152\r\n",
      "评估准确度: 0.969023 - 召回率: 0.965321 - f1得分: 0.967168\r\n",
      "训练集的当前epoch:2 - step:7\r\n",
      "损失函数: 3.205018\r\n",
      "训练集的当前epoch:2 - step:17\r\n",
      "损失函数: 5.393949\r\n",
      "训练集的当前epoch:2 - step:27\r\n",
      "损失函数: 2.191137\r\n"
     ]
    }
   ],
   "source": [
    "#设置Fine-Tune优化策略\n",
    "#1.计算了块检测的精确率、召回率和F1-score。常用于序列标记任务，如命名实体识别\n",
    "metric = ChunkEvaluator(label_list=label_vocab.keys(), suffix=True)\n",
    "#2.在Adam的基础上加入了权重衰减的优化器，可以解决L2正则化失效问题\n",
    "optimizer = paddle.optimizer.AdamW(learning_rate=2e-5, parameters=model.parameters())\n",
    "#损失函数由模型给出\n",
    "#3.\n",
    "#评估函数\n",
    "def evaluate(model, metric, data_loader):\n",
    "    model.eval()\n",
    "    metric.reset()#评估器复位\n",
    "    #依次处理每批数据\n",
    "    for input_ids, seg_ids, lens, labels in data_loader:\n",
    "        #CRF Loss\n",
    "        preds = model(input_ids, seg_ids, lengths=lens)\n",
    "        n_infer, n_label, n_correct = metric.compute(lens,preds,labels)\n",
    "        metric.update(n_infer.numpy(),n_label.numpy(),n_correct.numpy())\n",
    "        precision, recall, f1_score = metric.accumulate()    \n",
    "    print(\"评估准确度: %.6f - 召回率: %.6f - f1得分: %.6f\" % (precision, recall, f1_score))\n",
    "    model.train()\n",
    "#模型训练\n",
    "global_step = 0\n",
    "for epoch in range(20):\n",
    "    #依次处理每批数据\n",
    "    for step, (input_ids, segment_ids, seq_lens, labels) in enumerate(train_loader, start=1):\n",
    "        #直接得到CRF Loss\n",
    "        loss = model(input_ids, token_type_ids=segment_ids,lengths=seq_lens, labels=labels)\n",
    "        avg_loss = paddle.mean(loss)\n",
    "        avg_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "        if global_step % 10 == 0 :\n",
    "            print(\"训练集的当前epoch:%d - step:%d\" % (epoch, step))\n",
    "            print(\"损失函数: %.6f\" % (avg_loss))\n",
    "        global_step += 1\n",
    "    #评估训练模型\n",
    "    evaluate(model, metric, dev_loader)\n",
    "    paddle.save(model.state_dict(),\n",
    "            './checkpoint/model_%d.pdparams'  % (global_step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有什么问题，欢迎到评论区留言，我们一起讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
